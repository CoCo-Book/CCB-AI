{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 경로 설정 및 기본 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 경로 설정\n",
    "RAW_DIR = Path('raw')\n",
    "PROCESSED_DIR = Path('processed')\n",
    "RESULTS_DIR = Path('results')\n",
    "\n",
    "# 데이터 구조 정의\n",
    "class StoryData:\n",
    "    def __init__(self):\n",
    "        self.story_id = None\n",
    "        self.title = None\n",
    "        self.text = None\n",
    "        self.images = []\n",
    "        self.scene_descriptions = []\n",
    "        self.metadata = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    \"\"\"이미지 전처리 함수\n",
    "    - 이미지 크기 조정 (1024x1024) -> 모델 형식 (GPT-4o)\n",
    "    - 정규화\n",
    "    - 데이터 증강 \n",
    "    \"\"\"\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        # DALL-E 3 입력 형식에 맞게 조정\n",
    "        image = image.resize((1024, 1024))\n",
    "        # 이미지를 numpy 배열로 변환\n",
    "        image_array = np.array(image)\n",
    "        # 정규화 (0-1 범위로)\n",
    "        image_array = image_array / 255.0\n",
    "        return image_array\n",
    "    except Exception as e: # 예외 처리\n",
    "        print(f\"이미지 처리 중 오류 발생: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_image_features(image_array):\n",
    "    \"\"\"이미지 특징 추출 함수\n",
    "    - 이미지의 주요 특징 추출\n",
    "    - 스타일, 구도, 주요 객체 등 분석\n",
    "    \"\"\"\n",
    "    # TODO: 이미지 특징 추출 로직 구현\n",
    "    features = {\n",
    "        'composition': None,  # 구도 분석\n",
    "        'style': None,       # 스타일 분석\n",
    "        'objects': [],       # 주요 객체 목록\n",
    "        'colors': []         # 주요 색상 분포\n",
    "    }\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텍스트 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"텍스트 전처리 함수\n",
    "    - 특수문자 처리\n",
    "    - 문장 분리\n",
    "    - 토큰화\n",
    "    \"\"\"\n",
    "    # 기본 전처리\n",
    "    text = text.strip()\n",
    "    text = text.replace('\\n', ' ')\n",
    "    \n",
    "    # 문장 단위로 분리\n",
    "    sentences = text.split('.')\n",
    "    sentences = [s.strip() for s in sentences if s.strip()]\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "def extract_scene_descriptions(text):\n",
    "    \"\"\"장면 설명 추출 함수\n",
    "    - 텍스트에서 시각적 설명 부분 추출\n",
    "    - 장면별 설명 분리\n",
    "    \"\"\"\n",
    "    # TODO: 장면 설명 추출 로직 구현\n",
    "    scenes = []\n",
    "    return scenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋 생성 및 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(raw_data_path):\n",
    "    \"\"\"데이터셋 생성 함수\"\"\"\n",
    "    dataset = []\n",
    "    \n",
    "    # 원본 데이터 읽기\n",
    "    for story_dir in raw_data_path.glob('*'):\n",
    "        if not story_dir.is_dir():\n",
    "            continue\n",
    "            \n",
    "        story_data = StoryData()\n",
    "        \n",
    "        # 텍스트 데이터 읽기\n",
    "        text_path = story_dir / 'story.txt'\n",
    "        if text_path.exists():\n",
    "            with open(text_path, 'r', encoding='utf-8') as f:\n",
    "                story_data.text = f.read()\n",
    "                \n",
    "        # 이미지 처리\n",
    "        for img_path in story_dir.glob('images/*.jpg'):\n",
    "            processed_img = preprocess_image(img_path)\n",
    "            if processed_img is not None:\n",
    "                story_data.images.append(processed_img)\n",
    "                \n",
    "        dataset.append(story_data)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data(dataset):\n",
    "    \"\"\"학습 데이터 준비 함수\n",
    "    - 데이터 분할 (학습/검증/테스트)\n",
    "    - 데이터 포맷 변환\n",
    "    \"\"\"\n",
    "    # 데이터 분할\n",
    "    train_data, temp_data = train_test_split(dataset, test_size=0.3, random_state=42)\n",
    "    val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
    "    \n",
    "    # 데이터 포맷 변환\n",
    "    def format_data(data):\n",
    "        return [{\n",
    "            'text': item.text,\n",
    "            'images': item.images,\n",
    "            'scene_descriptions': item.scene_descriptions\n",
    "        } for item in data]\n",
    "    \n",
    "    return (\n",
    "        format_data(train_data),\n",
    "        format_data(val_data),\n",
    "        format_data(test_data)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # 데이터 전처리 파이프라인 실행\n",
    "    raw_data_path = RAW_DIR\n",
    "    processed_data = create_dataset(raw_data_path)\n",
    "    \n",
    "    # 학습/검증/테스트 데이터 준비\n",
    "    train_data, val_data, test_data = prepare_training_data(processed_data)\n",
    "    \n",
    "    # 처리된 데이터 저장\n",
    "    save_processed_data(processed_data, PROCESSED_DIR)\n",
    "    \n",
    "    # 데이터 검증\n",
    "    validation_results = validate_processed_data(PROCESSED_DIR)\n",
    "    \n",
    "    # 결과 저장\n",
    "    with open(RESULTS_DIR / 'preprocessing_results.json', 'w') as f:\n",
    "        json.dump(validation_results, f, indent=2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fairy_tail",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
